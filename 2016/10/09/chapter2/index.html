<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>机器学习 - chapter.2 | 旮哥日志</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.2.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.0.0/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">机器学习 - chapter.2</h1><a id="logo" href="/.">旮哥日志</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">机器学习 - chapter.2</h1><div class="post-meta">Oct 9, 2016<span> | </span><span class="category"><a href="/categories/机器学习/">机器学习</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><div class="post-content"><h1 id="模型评估与选择"><a href="#模型评估与选择" class="headerlink" title="模型评估与选择"></a>模型评估与选择</h1><h2 id="经验误差与过拟合"><a href="#经验误差与过拟合" class="headerlink" title="经验误差与过拟合"></a>经验误差与过拟合</h2><p><strong>错误率</strong>=分类错误的样本\总样本数 </p>
<p><strong>精度</strong>=1-错误率 </p>
<p>学习器的实际预测输出与样本的真实输出之间的差异被称为“<strong>误差</strong>” 学习器在训练集上的误差为“<strong>训练误差</strong>”、在新样本上的误差为“<strong>泛化误差</strong>” 我们的目标是让学习器的泛化误差最小，而实际上因为新样本的不确定，我们只能尽可能地让学习器的训练误差最小。 <strong>过拟合</strong>是指学习器在通过训练集样本进行训练时，学习能力过于强大，把那些只属于训练集的，但并非是一般化的特征也都学到了；相对于过拟合的概念就是欠拟合。 在现实生活中，对于某一问题，我们有多种可供选择的算法，而每个算法又因不同的参数配置产生出不同的模型。那么如何选择模型呢？其标准自然是选择泛化误差最小的，但我们却无法直接得到泛化误差；同时，训练误差也因为存在过拟合问题从而不适合作为标准。于是我们采取了一种评估方法，即，选用部分样本作为训练集，训练学习器，接下来将训练好的该学习器放在另一部分的样本（测试集）中进行测试，由此得到测试误差。我们将测试误差作为泛化误差的近似，从而对学习器的好坏进行评估。 如何将手头上的数据分为训练集和测试集进行测试，就要采用以下的方法：</p>
<h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><h3 id="留出法"><a href="#留出法" class="headerlink" title="留出法"></a>留出法</h3><p>将数据集（D）划分成两个互斥的部分，比如有1000个样本的数据集，选用其中的700个作为训练集，剩下的300个用作测试集。（划分数据集时要注意保持数据分布的一致性，即保证训练集和测试集是无差异的）。 之后计算测试误差，比如使用上述的700个样本的数据集D训练模型，将得到的模型在300个样本的测试集中进行测试，发现其将测试集中的90个样本分类错了。就可以得到错误率为90\/300=30%，那么，精度=1-错误率=70% 然后将划分过程随机重复多次，比如进行100次的划分。每次都得到一个错误率，最后留出法就是对这100个错误率进行平均，看所使用的模型的平均错误率有多高。 一般情况下，会将总样本中的2\/3~4\/5的样本用作训练集，余下的1\/3~1\/5作为测试集。</p>
<h3 id="交叉验证法"><a href="#交叉验证法" class="headerlink" title="交叉验证法"></a>交叉验证法</h3><p>留出法是划分为2个部分，而交叉法则是将数据D集划分为k个部分（k&gt;2），所以这一方法又被称为“k折交叉验证”。 比如一般会设置k=10，即划分为10个部分，之后就用9个（k-1个）当做训练集，剩下的1个做测试集。将这10份中，每个都作为测试集1次（其余的另9个作为训练集），就会得到10次结果。另外再把原数据集按照不同的划分方式再划分几次，比如5次，这样就会得到50个训练结果（5次×10折）。 交叉验证的一个极端的办法就是将数据集D（共包含m个样本）划分为m个部分，即k=m。这被称为“<strong>留一法</strong>”，每个子集中只有一个样本。这样训练集（k-1）≈总数据集（m），这样训练出的效果也就跟使用总数据集几乎是一个效果。但是当数据集中样本过大时，这样的计算量就过大了(如有1百万个数据样本就需要训练1百万个模型)。</p>
<h3 id="自助法"><a href="#自助法" class="headerlink" title="自助法"></a>自助法</h3><p>前两个方法由于保留了部分样本用于测试，因此实际评估的模型所使用的训练集比总数据集小。另外，尽管留一法受训练样本规模变化小，但是计算复杂度高。所以为了减少训练样本规模不同造成的影响，同时高效地进行试验估计，就采用自助法（bootstrapping） 对于包含m个样本的数据集D，使用自助采样法对其采样，产生新的数据集D’。 即，每次随机从D中挑选一个样本，放入D’中，然后将该样本再放回D中，再次从D中随机挑选出一个样本（刚才被挑选出的样本仍有可能再次被选到），放入D’中，不断重复这一过程m次。这样新生成的数据集D’中也就有了和D一样的样本个数。 因为是重复采样，所以仍然会有一些样本一次都没有被选入D’中，这一始终不被采样到的概率是$$(1−\frac{1}m)m$$,其极限为$$\frac{1}e$$(≈37%)。这样，始终不被采样的这37%的数据就可以用于测试集。 自助法在数据集较小，难以划分训练\/测试集时很有用。 但是，自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差。因此，在数据量足够时，更多会采用留出法和交叉验证法。</p>
<h3 id="调参与最终模型"><a href="#调参与最终模型" class="headerlink" title="调参与最终模型"></a>调参与最终模型</h3><p>大多数学习算法都有参数需要设定。在选择完算法后，对于算法的参数进行调节就是调参。 我们可以对一个算法中所需要的每种参数配置都训练出模型，然后挑选出最好的模型中所使用的参数。 然而现实中，试遍所有参数几乎是不可能的，于是我们就会对每个参数选定一个范围和变化步长进行计算。比如在[0，0.2]的范围内以0.05为步长，测试0，0.05，0.10，0.15，0.20这五个参数。然后从这5个数中选择最合适的。 当算法和参数已经选定好之后，这时需要再用所有的数据m，即用整个数据集D来再度训练模型。</p>
<h2 id="性能度量"><a href="#性能度量" class="headerlink" title="性能度量"></a>性能度量</h2><p>衡量模型能力的泛化能力的评价标准就是<strong>性能度量</strong>。在对比不同的模型能力的时候，使用不同的性能度量往往会导致不同的评判结果。<br>我们使用<strong>均方误差</strong>来对学习器的性能进行度量，即，学习器(f)对每个样本($$x_i$$)计算得到的数值($$f(x_i)$$)与真实数值($$y_i$$)进行比较，得到预测值与真实值的误差，然后对每个样本计算得到的误差进行求和，最后再求出均值。</p>
<p>均方误差=$$\frac{1}m\sum_{i=1}^{m}(f(x_i)-y_i)^2$$</p>
<h3 id="错误率与精度"><a href="#错误率与精度" class="headerlink" title="错误率与精度"></a>错误率与精度</h3><p>结合本章开头提到的错误率与精度，对于数据集D：</p>
<p>分类错误率=$$\frac{1}m\sum_{i=1}^{m}Ⅱ(f(x_i)\not=y_i)$$</p>
<p>(Ⅱ在这里表示指示函数，即它后面的函数取值或者为0，或者为1)</p>
<p>精度=1-分类错误率=分类错误率=$$\frac{1}m\sum_{i=1}^{m}Ⅱ(f(x_i)=y_i)$$</p>
<h3 id="查准率、查全率与F1"><a href="#查准率、查全率与F1" class="headerlink" title="查准率、查全率与F1"></a>查准率、查全率与F1</h3><p>错误率与精度虽然常用，但是并不能满足所有任务需求。有时我们希望知道的是“被当作好西瓜挑出来的西瓜中确实是好西瓜的比例”或者“真正的好瓜中有多少是被伯乐挑出来了”。此时就会出现四种情况。</p>
<p>真正例（TP：好的西瓜，并且模型也认为是好的西瓜）</p>
<p>假正例（FP：坏的西瓜，但是模型认为是好的西瓜）</p>
<p>假反例（FN：好的西瓜，但是模型认为是坏的西瓜）</p>
<p>真反例（TN：坏的西瓜，并且模型也认为是坏的西瓜）<br>于是有：</p>
<p>查准率Precision=$$\frac{真正例（TP）}{真正例（TP）+假正例（FP）}$$；即，被当作好西瓜挑出来的西瓜中确实是好西瓜的比例</p>
<p>查全率Recall=$$\frac{真正例（TP）}{真正例（TP）+假反例（FN）}$$；即，真正的好瓜中有多少是被伯乐挑出来了</p>
<p>查准率与查全率是对矛盾的度量。因为比如查准率高，就意味着模型越保守，只会选择那些非常有把握的瓜，这样漏掉的好瓜也会增多。<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/350px-Precisionrecall.svg.png" alt="Wikipedia对于两个比率的非常形象的说明"></p>
<p>如果我们有多个模型，则可以分别计算每个模型的查准率和查全率来比较模型的好坏。比如，我们有一个模型A来预测西瓜的好坏，对于每个样本（100个）输入，它输出一个计算结果（模型的预测值100个，即每个瓜的得分）。我们将这100的得分从大到小排序，分数越大的瓜就表示模型预测这个瓜更好。这时我们来设定阈值，比如好瓜的得分标准是60分，80分还是90分等等。每设定一个阈值（相当于将上图中间的区分左右两边颜色的竖线从最左一直移到最后），就可以计算出一次该阈值下，模型A的好坏瓜预测情况的查准率和查全率。如下图中的左图所示，横轴是查全率，纵轴是查准率，绿色曲线是模型A的数值变化，蓝线是模型B。判断这两个模型的好坏，只要看哪一个曲线在外面就可以了，因为在外面的曲线上任选一点，得到一对查准率和查全率，里面曲线上具有相同查准率（or查全率）的那一点，它相应的查全率（or查准率）肯定要小于外面曲线上的。</p>
<p><img src="http://images.slideplayer.com/12/3430573/slides/slide_87.jpg" alt="查准率与查全率曲线"></p>
<p>我们在该图上如果画上函数y=x的直线，那么该直线与模型A（绿色）和B（蓝色）的曲线的交点就是在该曲线上查全率=查准率的点（平衡点 Break-Even Point）。显然可以发现，绿色曲线的平衡点的数值肯定要小于蓝色曲线的（该点上绿色曲线的查准率和查全率都要高于蓝色曲线），于是就可以判断，蓝色曲线（模型B）要优于绿色曲线（模型A）。</p>
<p>除了比较平衡点之外，更常用的是被称为F1度量的办法来比较不同的模型的优劣。<br>$$F1=\frac{2×查准率×查全率}{查准率+查全率}=\frac{2×真正例}{总样本数+真正例-真反例}$$</p>
<p>实际上，F1的含义如下</p>
<p>$$\frac1{F1}=\frac1{2}(\frac1{查准率}+\frac1{查全率})$$，本质上还是平衡点，只是这一公式比算术平均（$$\frac{查准率+查全率}2$$）或者几何平均($$\sqrt{查准率×查全率}$$)更重视最小值。</p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="https://justin007755.github.io/2016/10/09/chapter2/" data-id="ciu216apn0000ogfswwt11tv5" class="article-share-link">分享到</a><div class="tags"><a href="/tags/机器学习/">机器学习</a></div><div class="post-nav"><a href="/2016/09/26/演讲学习笔记-2/" class="next">演讲学习笔记_2</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://justin007755.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/IT技术/">IT技术</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/写作/">写作</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/演讲/">演讲</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/践行/">践行</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/随笔/">随笔</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/随笔/" style="font-size: 15px;">随笔</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/思考/" style="font-size: 15px;">思考</a> <a href="/tags/社群/" style="font-size: 15px;">社群</a> <a href="/tags/演讲/" style="font-size: 15px;">演讲</a> <a href="/tags/写作/" style="font-size: 15px;">写作</a> <a href="/tags/Github/" style="font-size: 15px;">Github</a> <a href="/tags/MOOC/" style="font-size: 15px;">MOOC</a> <a href="/tags/读书/" style="font-size: 15px;">读书</a> <a href="/tags/IoT/" style="font-size: 15px;">IoT</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2016/10/09/chapter2/">机器学习 - chapter.2</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/26/演讲学习笔记-2/">演讲学习笔记_2</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/21/演讲学习笔记-1/">演讲学习笔记_1</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/05/改变自己/">老司机要学会改变自己</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/08/24/写作课笔记-4/">写作课笔记_4</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/08/11/用Hexo在Github上搭建自己的博客-2/">用Hexo在Github上搭建自己的博客-2</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/07/28/写作课笔记-3/">写作课笔记_3</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/07/24/写作课笔记-2/">写作课笔记_2</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/07/22/用Hexo在Github上搭建自己的博客-1/">用Hexo在Github上搭建自己的博客-1</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/07/13/写作课笔记-1/">写作课笔记_1</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://http://xiaolai.li/" title="李笑来，人人都是工程师" target="_blank">李笑来，人人都是工程师</a><ul></ul><a href="http://www.yangzhiping.com/" title="阳志平的网志" target="_blank">阳志平的网志</a><ul></ul><a href="http://www.ruanyifeng.com/blog/" title="阮一峰的网络日志" target="_blank">阮一峰的网络日志</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">旮哥日志.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>