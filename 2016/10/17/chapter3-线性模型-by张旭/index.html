<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>机器学习 - chapter.3 | 旮哥日志</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.2.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.0.0/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">机器学习 - chapter.3</h1><a id="logo" href="/.">旮哥日志</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">机器学习 - chapter.3</h1><div class="post-meta">Oct 17, 2016<span> | </span><span class="category"><a href="/categories/机器学习/">机器学习</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><div class="post-content"><p><strong>（本文为张旭的读书笔记）</strong></p>
<h1 id="线性模型"><a href="#线性模型" class="headerlink" title="线性模型"></a>线性模型</h1><h2 id="1-基本概念"><a href="#1-基本概念" class="headerlink" title="1. 基本概念"></a>1. 基本概念</h2><p><u>什么是线性模型(linear model)？</u></p>
<p>就是通过一个属性（即特征，feature）的线性组合来进行预测的函数，即<br>$$f(x)=\omega_1x_1+\omega_2x_2+…+\omega_dx_d+b$$</p>
<p>一般向量形式可以写成$$f(x)=\omega^Tx+b$$<br>其中$$\omega=(\omega_1;\omega_2;…;\omega_d)$$</p>
<p>ω和b学得之后，模型就得以确定。即对于每一个新的测试样本，其特征（x向量）一定的情况下（通过特征提取得到），由这个确定的线性模型即可得到预测结果（f(x)）。<br>以书中的西瓜位例，给出一个新的西瓜，通过其特征数据（色泽，根蒂，敲声）以及这个训练好的线性模型（如下），即可得到预测结果（f(x)）：好瓜还是坏瓜。<br>$$f_{好瓜}(x)=0.2x_c+0.5x_r+0.3x_s+1$$</p>
<p><u>再进一步，什么是线性函数？</u>  </p>
<p>根据维基百科，线性函数在数学上是两个不同但相关的概念。在算数里，它表示一个一次或零次多项式，如果仅有一个自变量，则表示为f(x)=ax+b，如果有多个自变量，则表示为$$f(x_1,…,x_k)=b+a_1x_1+…+a_kx_k$$（几何图象上这是一个k维的超平面）。<br>在线性代数里，它表示两个向量空间的映射，向量相加（<a href="https://en.wikipedia.org/wiki/Vector_addition" target="_blank" rel="external">vector addition</a>）或者纯量乘法（<a href="https://en.wikipedia.org/wiki/Scalar_multiplication" target="_blank" rel="external">scalar multiplication</a>）<br>f(x+y)=f(x)+f(y)<br>f(ax)=af(x)</p>
<h2 id="2-线性回归"><a href="#2-线性回归" class="headerlink" title="2. 线性回归"></a>2. 线性回归</h2><p><u>什么是线性回归（linear regression）？</u></p>
<p>回归，是确定两种或两种以上变量间（解释变量）相互依赖的定量关系的一种统计方法。更精确地定义是指研究一组随机变量(Y1 ，Y2 ，…，Yi)和另一组(X1，X2，…，Xk)变量之间关系的统计分析方法，又称多重回归分析。通常Y1，Y2，…，Yi是因变量，X1、X2，…，Xk是自变量。</p>
<p>“线性回归”试图学得一个线性模型以尽可能准确地预测实值输出标记。这里的“实值”指的是测试样本，“标记“指的是预测的结果（比如好瓜）。所以，回归问题的学习其实等价于函数拟合，选择一条函数曲线使其很好地拟合已知数据且很好地预测未知数据。</p>
<blockquote>
<p>扩展（来自百度百科）：相关分析研究的是现象之间是否相关、相关的方向和密切程度，一般不区别自变量或因变量。而回归分析则要分析现象之间相关的具体形式，确定其因果关系，并用数学模型来 表现其具体关系。比如说，从相关分析中我们可以得知“质量”和“用户满意度”变量密切相关，但是这两个变量之间到底是哪个变量受哪个变量的影响，影响程度如何，则需要通过回归分析方法来确定。</p>
<p>一般来说，回归分析是通过规定因变量和自变量来确定变量之间的因果关系，建立回归模型，并根据实测数据来求解模型的各个参数，然后评价回归模型是否能够很好的拟合实测数据；如果能够很好的拟合，则可以根据自变量作进一步预测。</p>
</blockquote>
<p><u>如何求解线性回归函数？</u>  </p>
<p>先把要求解的现实问题简化。首先，把模式空间的纬度限定在一维，即取一个属性/特征变量，比如书中提到的“身高”或者“瓜类”等等。然后通过预处理，把属性/特征的取值量化。求解的目标是$$f(x_i)=\omega \times x_i+b$$,使得$$f(x_i)\approx y_i$$。<br>其中$$y_i$$是训练/测试数据的实际标记，$$f(x_i)$$是通过该线性模型算出的。如何确定ω和b呢？显然，关键在于如何衡量f(x)与y之间的差别。在回归任务中，均方误差是最常用的性能度量（why？见下面的斜体说明），因此可以让均方误差最小化，即<br>$$(\omega^\ast,b^\ast)=argmin\sum_1^m(f(x_i)-y_i)^2<br>                      =argmin\sum_1^m(y_i-\omega \times x_i-b)^2$$</p>
<blockquote>
<p>这里实际上需要进一步阐明一下，如何在模型的假设空间（由输入空间到输出空间的映射集合，即所有可能的模型函数，Y=f(X)）里按照什么样的准则学习或者选择最优的模型，即策略。这部分可以参考李航的《统计学习方法》，里面第一章描述了损失函数与风险函数的概念。损失函数是度量模型一次预测的好坏，风险函数度量平均意义下模型预测的好坏。<br>监督学习问题是在假设空间中选取模型作为决策函数，对于给定的输入X，由f(X)给出相应的输出Y，这个输出的预测值f(X)与真实值Y可能不一致，用一个损失函数（loss function）或者代价函数（cost function）来度量预测错误的程度。损失函数是f(X)和Y的非负实值函数。可以记录作“L(Y,f(X))”。常用的有“0-1损失函数”，“平方损失函数”等等。损失函数值越小，模型就越好。<font color="red">不同的问题应该采用不同的损失函数作为策略。</font></p>
</blockquote>
<p><u>再进一步，什么是均方误差MSE（Mean Squared Error）？</u></p>
<p>计算公式如下：$$E(f;D)=\frac 1m\sum_1^m(f(x_i)-y_i)^2$$<br>更一般的，对于数据分布Ɗ和概率密度函数p(.)，均方误差可描述为:$$E(f;D)=\int_1^D(f(x)-y)^2p(x)dx$$</p>
<p>方差是在概率论和统计方差衡量随机变量或一组数据的离散程度的度量方式，方差越大，离散度越大。求解方式为，各随机变量与平均值差值的平方和的平均数（先求差，再平方，再平均）</p>
<p>从资料上看，均方误差和方差的英文表述不一样（在维基百科能体现），但是计算公式基本相同，可能有一些细微的差别，<font color="red">待查？</font></p>
<blockquote>
<p>Mean squared error（均方误差）：In statistics, the mean squared error (MSE) or mean squared deviation (MSD) of an estimator (of a procedure for estimating an unobserved quantity) measures the average of the squares of the errors or deviations—that is, the difference between the estimator and what is estimated.</p>
<p>Variance（方差）：In probability theory and statistics, variance is the expectation of the squared deviation of a random variable from its mean, and it informally measures how far a set of (random) numbers are spread out from their mean.</p>
</blockquote>
<p>标准差（standard deviation）等同于均方根误差（root-mean-square deviation）：</p>
<blockquote>
<p>The root-mean-square deviation (RMSD) or root-mean-square error (RMSE) is a frequently used measure of the differences between values (sample and population values) predicted by a model or an estimator and the values actually observed. The RMSD represents the sample standard deviation of the differences between predicted values and observed values.</p>
<p>In statistics, the standard deviation (SD, also represented by the Greek letter sigma σ or the Latin letter s) is a measure that is used to quantify the amount of variation or dispersion of a set of data values.</p>
</blockquote>
<p>均方误差有非常好的几何意义，它对应了常用的欧几里得距离或简称“欧氏距离”。基于均方误差最小化来进行模型求解的方法称为“最小二乘法”。在线性回归中，最小二乘法就是试图找到一条直线，使所有样本到直线上的欧氏距离之和最小。<font color="red">这里的均方误差最小化即上面提到的平方损失函数？</font></p>
<p>所以变成了求解ω和b使$$E(\omega,b)=\sum_1(y_i-\omega \times -b)^2$$最小化的过程，称为线性回归模型的最小二乘“参数估计”。 把ω和b看作是E的函数，就变成了一个求极值的问题，可以通过求导数得到。根据数学知识我们知道，函数的极值点为偏导为0的点。这就是最小二乘法的解法，就是求得平方损失函数的极值点。这里$$E(\omega,b)$$也是关于ω和b的凸函数，当它关于ω和b的导数均为零时，得到ω和b的最优解。<br>求解结果如下：$$\omega=\frac {\sum_1^my_i(x_i-\overline{x})}{\sum_1^mx^2-\frac 1m(\sum_1^mx_i)^2}$$</p>
<blockquote>
<p><img src="http://latex.codecogs.com/gif.latex? \theta_j:=\theta_j+\alpha(y^{(i)}-h_{\theta}(x^{(i)}))x_j^{(i)}"></p>


</blockquote>
<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>




</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="https://justin007755.github.io/2016/10/17/chapter3-线性模型-by张旭/" data-id="ciy9r5ktd000i1kfs9xyq07zs" class="article-share-link">分享到</a><div class="tags"><a href="/tags/机器学习-ViaWorks/">机器学习 ViaWorks</a></div><div class="post-nav"><a href="/2017/01/23/未来论坛年会--未来智能讨论/" class="pre">未来论坛年会 -- 未来智能交流</a><a href="/2016/10/17/chapter2-模型评估与选择-by范宏伟/" class="next">机器学习 - chapter.2</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://justin007755.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/IT技术/">IT技术</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/写作/">写作</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/演讲/">演讲</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/读书/">读书</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/践行/">践行</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/随笔/">随笔</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/社群/" style="font-size: 15px;">社群</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/思考/" style="font-size: 15px;">思考</a> <a href="/tags/写作/" style="font-size: 15px;">写作</a> <a href="/tags/读书/" style="font-size: 15px;">读书</a> <a href="/tags/机器学习-ViaWorks/" style="font-size: 15px;">机器学习 ViaWorks</a> <a href="/tags/MOOC/" style="font-size: 15px;">MOOC</a> <a href="/tags/随笔/" style="font-size: 15px;">随笔</a> <a href="/tags/演讲/" style="font-size: 15px;">演讲</a> <a href="/tags/Github/" style="font-size: 15px;">Github</a> <a href="/tags/IoT/" style="font-size: 15px;">IoT</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2017/03/19/bigdata2_2/">bigdata2_2</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/01/23/未来论坛年会--未来智能讨论/">未来论坛年会 -- 未来智能交流</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/17/chapter3-线性模型-by张旭/">机器学习 - chapter.3</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/17/chapter2-模型评估与选择-by范宏伟/">机器学习 - chapter.2</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/13/演讲学习笔记-3&4/">演讲学习笔记_3&4</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/10/如何有效读一本书/">如何有效读一本书</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/26/演讲学习笔记-2/">演讲学习笔记_2</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/21/演讲学习笔记-1/">演讲学习笔记_1</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/05/改变自己/">老司机要学会改变自己</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/08/24/写作课笔记-4/">写作课笔记_4</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://http://xiaolai.li/" title="李笑来，人人都是工程师" target="_blank">李笑来，人人都是工程师</a><ul></ul><a href="http://www.yangzhiping.com/" title="阳志平的网志" target="_blank">阳志平的网志</a><ul></ul><a href="http://www.ruanyifeng.com/blog/" title="阮一峰的网络日志" target="_blank">阮一峰的网络日志</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">旮哥日志.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>